1、JVM
	运行时数据区内存模型
	1）程序计数器
		在线程中，记录每个线程当前执行的语句行书，每个线程都有。
	2）Java虚拟机栈
		线程私有，生命周期和线程一致。每个方法在执行时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。
	3）本地方法栈
		本地方法栈是在JVM调用本地的native方法的时候会使用的栈，JDK源码中使用native修饰的方法，直接调用操作系统的方法，JVM只是获取返回值。
	4）Java堆
		堆用来存储new创建的对象，堆分为新生代和老年代，新生代又分为Eden区占据新生代80%的空间，另一部分为Survivor空间，两个Survivor空间各占10%。
	5）方法区
		属于共享内存区域，存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。
		从JDK 1.8开始，方法区不再作为JVM内存中的一部分，而是将方法区放在本地内存上，作为元空间，这样的好处在于降低了方法区OOM的可能性。
		方法区主要加载了类的信息，如果加载的类过多，类信息过大容易导致方法区OOM。

	垃圾回收器：
		目前常用垃圾收集器：CMS、G1。当然，根据不同的场景可以选择适用的垃圾回收器，可以根据压测数据判断，业务场景合适的垃圾收集器。
		CMS：以获得最短回收停顿时间为目标的收集器，标记清除算法。过程：初始标记，并发标记，重新标记，并发清除。
		G1：分成很多个单独的块，标记整理算法实现。过程：初始标记，并发标记，最终标记，筛选回收。
		CMS收集器和G1的区别：
		1）CMS收集器是老年代的收集器，可以配合新生代的Serial和ParNew收集器一起使用；
		2）G1收集器收集范围是老年代和新生代，不需要结合其他收集器使用；
		3）CMS收集器以最小的停顿时间为目标的收集器；
		4）CMS收集器使用的是“标记-清除”算法，容易产生内存碎片；
		5）G1收集器使用的是“标记-整理”算法，进行空间整合，降低了内存空间碎片。

	类加载机制、类加载器、字节码这几个方面了解的比较少，结课后需要复习的方向与内容。
	JVM调优，线上没有什么调优的经验，需要根据老师的方法，对一些项目进行压测，使用不同的垃圾收集器，不同的堆内存大小，新生代内的比例等，去实验，总结。


2、NIO
	在学习过程中对NIO映像比较深的知识点：Reactor模型
	实际上的Reactor模式，是基于Java NIO的，在他的基础上，抽象出来两个组件——Reactor和Handler两个组件：
		1）Reactor：负责响应IO事件，当检测到一个新的事件，将其发送给相应的Handler去处理；新的事件包含连接建立就绪、读就绪、写就绪等。
		2）Handler:将自身（handler）与事件绑定，负责事件的处理，完成channel的读入，完成处理业务逻辑后，负责将结果写出channel。
		
	Netty是对NIO实现非常好的框架，有个必做作业是，使用Netty实现HttpClient。复习的时候，完成这个必做作业。


3、并发编程
	1）了解了创建线程的几种方式，线程的五种运行状态：新建、就绪、运行、阻塞、死亡；
	2）sychronized同步块，保证多线程中只能有一个线程执行；
	3）volatile保证可见性，但不保证原子性；
	4）Atomic类，CAS自旋的方式保证线程安全；
	5）Lock 学习了悲观锁、乐观锁、读写锁等使用API；
	6）线程间协作，好玩的东西：CountDownLatch、CyclicBarrier、semaphore；
	7）java集合类、并发队列、线程池等等。

	这里面的每一项都需要再次深入的学习下，关于核心线程数配置的经验值：CPU密集型：线程数和CPU数相同；IO密集：线程数=2*CPU。
	但可以根据业务场景，使用不同的配置，通过压测去确定最终的配置值。


4、Spring和ORM等框架
	Spring框架内容特别多，从事java程序开发开始就一直在用，一直都是属于使用Api的程度，通过网上的例子，或是项目搭好的框架就直接用了。
	包括Mybatis框架也是，从未想过配置是如何生效的。Spring容器是如何加载、管理Spring的Bean，组件，配置等。
	手写了Spring-starter，spring-boot约定大于配置。Spring IOC，动态代理还有好多的知识点需要重新去复习，深挖......
	Mybatis平常用的也是比较多，但基本都是用配置文件的方式去做的Mapper.xml，使用#防止数据库注入功能。


5、MySQL数据库和SQL
	MySQL数据库也是从工作以来一直在使用的数据库。列举一下自己了解的优化方案：
	1）添加索引，索引数量控制在3个以内，了解索引失效原因；
	2）开启慢查询日志，对SQL语句explain，分析执行范围等；
	3）判断是否需要开启MySQL缓存，调优参数设置等；
	3）优化子查询，检查limit。
	不了解的内容：
	1）redo log、undo log、间隙锁；
	2）如何避免锁表、锁库；
	3）B+树。

	MongDB：最近做一个功能使用到了MongDB，大概有1.5亿的数据，MongDB 3.x的版本，线上环境没有开启自动创建索引，即使代码中使用了@Index注解创建索引，
	但是线上并没有创建，导致查询极度缓慢，把整个MongDB集群的吞吐都卡住了，后面运维同事手动加上索引就好了。关于代码使用@Index注解，却实际未创建索引的问题，
	复习到这一点的时候，在本地试试。
	Redis：redis的IO线程是多线程的，执行线程是单线程，所以执行redis的命令不能有阻塞。
		   也是线上的例子：map，定时任务，每十分钟要取出并删除map里面的所有数据，为了防止一下子取出大数据，导致阻塞，使用redis的scan方法，分批取出，再分片删除key。
		   而且定时任务只能一台服务器执行，要使用redis分布式锁。（虽然公司已经封装好了，不过写过作业，再去看源码，就好懂多了。）


6、分库分表
	在以前小公司的时候，最常用的分库分表就是按日期分表，每日、每周、每月。这通常是用在日志库，这样分的好处就是减少单表的数据量，提高执行SQL的效率，同时根据日期也方便查找对应的数据。
	游戏公司的分库方法是根据服务器，不同服务器，不同数据库，但合服的时候，数据会越滚越大，而且容易id冲突，还需要运维定期清除僵尸数据。
	如果一开始就对用户数据分表，并且对id使用雪花算法，这样可以避免id冲突，合服后，单表的数据也容易增长太快。
	单库分表并不能解决连接数多的问题，因为用的还是同个数据源，需要用到主从库，读写分离，如果数据量大，并发大，可以用到数据库集群。
	分库分表的中间件使用sharding-sphere，不过我们公司还在用原始的sharding-jdbc，后面因为 or 不支持，升级到了sharding-sphere 3.x的版本。
	sharding-sphere的源码，基本上没看，o(╥﹏╥)o，愧对秦老师。


7、RPC和微服务
	之前在游戏公司的时候，多个服务间通信，更多是用netty通信，根据协议号去执行对应的方法；也有向redis发布，另一个服订阅发布，然后执行方法。
	目前公司使用dubbo-rpc，使用上简单很多，回想起来，其实也是可以用在游戏的项目，provider提供接口，相应的服务器去消费，但是要注意游戏服有状态的问题，
	目前的思考是需要用到redis集群，可能结合不同业务场景的时候有不一样的解决方案。
	据我所知大多数游戏公司并没有用到微服务（可能是我孤陋寡闻），以我目前的知识理解：微服务是无状态的，可以随时重启更新，容易扩容；
	游戏服很多有状态，例如玩家在组队中，玩家在同个地图，需要同步周围玩家等等场景。游戏服起码需要一个路由，把组队，组团的玩家聚合在同一个服。
	当然办法总比困难多，应该也是可以通过网关限流，把用户迁移到另一个服，也许我考虑的并不周全。

	微服务：以目前遇到的举个例子：用户、任务、视频、排行榜、风控、资源、推荐、认证、用户成长、活动等模块划分为一个个服务。
	以多活的形式部署，一个集群，三个服务。用户服务达到了9个，因为几乎所有的服都需要调用用户服务，并发量比较高。
	我的理解就是，当用户量上来了，单机的服务器无法支持高并发，那么可以根据业务功能拆分多个模块，每个模块都是一个微服务，当一个服务不足以支撑的时候，就用集群，
	也可以继续扩容。防止某些机房整体挂掉，可以采用多活的形式（主备），去支持线上环境。


8、分布式缓存
	分布式缓存，学完之后基本上只记得redis缓存和网格缓存？又......还给秦老师了o(╥﹏╥)o......
	学习之后，才知道redis也可以配置主从，可以实现读写分离。还可以配置sentinel，实现redis主从自动的切换达到如丝般顺滑。
	redis集群，RedisCluster，redis分布式锁。好像就记得这些......不写了，准备回看资料和视频。	


9、分布式消息队列
	这个课的视频看完了，作业没有做......落下了。
	目前项目上用到的几个场景：
	1、异步队列的使用，对当前线程阻塞比较大的功能（例如数据库批量操作），先放到MQ，再由消费者慢慢去处理这些耗时操作；
	2、某个服产生的消息，其他微服务订阅该消息，消费处理；
	3、业务间解耦（其实跟2应该是一样的），例如活动平台发布一些活动消息，业务方可以订阅处理该活动，也可以参与这些活动。

	目前我只用到了RocketMQ，设置分组、tag，消费者设置分组，根据不同的tag处理自己要处理的消息。
	现在自己理解的内容只有这么多，后续还需努力，深入学习。
